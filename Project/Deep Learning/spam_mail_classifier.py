# -*- coding: utf-8 -*-
"""Spam mail classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZXpOnakt2Zi5TagiNT3dD86HUCwY6R8N
"""

import pandas as pd
import numpy as np
import nltk

df = pd.read_csv(r"/content/drive/My Drive/Spam_SMS_dataset/SMSSpamCollection", sep="\t", names = ['labels', 'message'] )

nltk.download('stopwords')
import re

import nltk
nltk.download('wordnet')

from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
lm = WordNetLemmatizer()

corpus = []

for i in range(len(df)):
  review = re.sub('[^a-zA-Z]', ' ', df['message'][i])
  review = review.lower()
  review = review.split()
  review = [lm.lemmatize(word) for word in review if word not in stopwords.words('english')]
  review = ' '.join(review)
  corpus.append(review)

#creating bag of words model

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=4000)
X = cv.fit_transform(corpus).toarray()

y = pd.get_dummies(df['labels'])
y = y.iloc[:,1]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0)

from sklearn.naive_bayes import MultinomialNB
spam_detect = MultinomialNB().fit(X_train, y_train)

y_spam =spam_detect.predict(X_test)

from sklearn.metrics import mean_squared_error
mean_squared_error(y_test, y_spam)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_spam)

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_spam)

"""### **We have got 98.33 percent using Naive Bayes Classifier Now We'll try with LSTM technique.**"""



import tensorflow as tf

from tensorflow.keras.layers import Dense, Embedding, LSTM
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.sequence import pad_sequences

tf.__version__

voc_size = 10000

onehot = [one_hot(words, voc_size) for words in corpus]
onehot

# Embedding Representation

sent_length = 150 
embedded_docs = pad_sequences(onehot, padding = 'pre', maxlen = sent_length)
print(embedded_docs)

embedding_vector_feature = 60

model = Sequential()
model.add(Embedding(voc_size, embedding_vector_feature, input_length=sent_length))
model.add(LSTM(100))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics =['accuracy'])
print(model.summary())

import numpy as np
X_final = np.array(embedded_docs)
y_final = np.array(y)

# splitting into train and test data

 from sklearn.model_selection import train_test_split

 X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.2, random_state=42)

model.fit(X_train, y_train, epochs = 15, batch_size = 64)

ypred = model.predict_classes(X_test)

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, ypred)

from sklearn.metrics import accuracy_score

accuracy_score(y_test, ypred)

# accuracy of LSTM is 99 pecent